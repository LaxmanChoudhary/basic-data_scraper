{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get page source\n",
    "from urllib.request import urlopen as uReq, Request, urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing beautifulSoup for beautifying the html\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of page\n",
    "url= \"https://www.superdatascience.com/deep-learning/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requesting page using- Request with specific user agent\n",
    "\"\"\"\n",
    "This could be done using,\n",
    "\n",
    "Page = uReq(url)\n",
    "webpage = Page.read()\n",
    "\n",
    "where both 'webpage' delievers the same result\n",
    "but this method many times return Error 403: Forbidden\n",
    "that is due to outdated User-Agent, so use below method for those that don't work by normal procedure\n",
    "\"\"\"\n",
    "Req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "# uReq() = urllib.requests.urlopen\n",
    "Page = uReq(Req).read()\n",
    "\n",
    "webpage = Page.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html parsing- let's us add more functionalities to the html code\n",
    "pageSoup = soup(webpage, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>Deep Learning A-Z™: Download Practice Datasets</h1>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one of the use is that we can grap the text and links etc. using the html tags after passed in bs4\n",
    "# need basic knowledge of the parsing type, here html\n",
    "\n",
    "# shows header in pageSoup\n",
    "pageSoup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Welcome to the data repository for the Deep <span>Learning course</span> by Kirill Eremenko and Hadelin de Ponteves.</p>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows paragraph in soup object\n",
    "pageSoup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the href tag containing pdf in link\n",
    "def pdf_href(href):\n",
    "    return href and re.compile(\"pdf\").search(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the lines of html code havinf .pdf link in pdf_links\n",
    "pdf_links = pageSoup.find_all(href=pdf_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing list of text type titles in each line in pdf_links \n",
    "pdf_title = []\n",
    "\n",
    "for each in pdf_links:\n",
    "    pdf_title.append(each.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Efficient BackProp',\n",
       " 'Deep sparse rectifier neural networks',\n",
       " 'Gradient-Based Learning Applied to Document Recognition',\n",
       " 'Introduction to Convolutional Neural Networks',\n",
       " 'Understanding Convolutional Neural Networks with A Mathematical Model',\n",
       " 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification',\n",
       " 'Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition',\n",
       " 'Untersuchungen zu dynamischen neuronalen Netzen',\n",
       " 'Learning Long-Term Dependencies with Gradient Descent is Difficult',\n",
       " 'On the difficulty of training recurrent neural networks',\n",
       " 'Long Short-Term Memory',\n",
       " 'Visualizing and Understanding Recurrent Networks',\n",
       " 'LSTM: A Search Space Odyssey',\n",
       " 'Deep sparse rectifier neural networks',\n",
       " 'The Self-Organizing Map',\n",
       " 'A Tutorial on Energy-Based Learning',\n",
       " 'A fast learning algorithm for deep belief nets',\n",
       " 'Notes on Contrastive Divergence',\n",
       " 'Greedy Layer-Wise Training of Deep Networks',\n",
       " 'The wake-sleep algorithm for unsupervised neural networks',\n",
       " 'Deep Boltzmann Machines',\n",
       " 'k-Sparse Autoencoders',\n",
       " 'Extracting and Composing Robust Features with Denoising Autoencoders',\n",
       " 'Contractive Auto-Encoders: Explicit Invariance During Feature Extraction',\n",
       " 'Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion',\n",
       " 'Reducing the Dimensionality of Data with Neural Networks',\n",
       " 'API-Updates']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing links in a list\n",
    "links_only=[]\n",
    "\n",
    "for each in pdf_links:\n",
    "    links_only.append(each[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf',\n",
       " 'http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf',\n",
       " 'http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf',\n",
       " 'http://cs.nju.edu.cn/wujx/paper/CNN.pdf',\n",
       " 'https://arxiv.org/pdf/1609.04112.pdf',\n",
       " 'https://arxiv.org/pdf/1502.01852.pdf',\n",
       " 'http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf',\n",
       " 'http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf',\n",
       " 'http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf',\n",
       " 'http://www.jmlr.org/proceedings/papers/v28/pascanu13.pdf',\n",
       " 'http://www.bioinf.jku.at/publications/older/2604.pdf',\n",
       " 'https://arxiv.org/pdf/1506.02078.pdf',\n",
       " 'https://arxiv.org/pdf/1503.04069.pdf',\n",
       " 'http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf',\n",
       " 'http://sci2s.ugr.es/keel/pdf/algorithm/articulo/1990-Kohonen-PIEEE.pdf',\n",
       " 'http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf',\n",
       " 'https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf',\n",
       " 'http://www.robots.ox.ac.uk/~ojw/files/NotesOnCD.pdf',\n",
       " 'http://www.iro.umontreal.ca/~lisa/pointeurs/BengioNips2006All.pdf',\n",
       " 'http://www.gatsby.ucl.ac.uk/~dayan/papers/hdfn95.pdf',\n",
       " 'http://www.utstat.toronto.edu/~rsalakhu/papers/dbm.pdf',\n",
       " 'https://arxiv.org/pdf/1312.5663.pdf',\n",
       " 'http://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf',\n",
       " 'http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Rifai_455.pdf',\n",
       " 'http://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf',\n",
       " 'https://www.cs.toronto.edu/~hinton/science.pdf',\n",
       " 'http://www.superdatascience.com/wp-content/uploads/2017/03/API-Updates.pdf']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\".\\DL research papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(pdf_links)):\n",
    "    f_name = pdf_title[i]+\".pdf\"\n",
    "    with open(f_name, 'wb') as file:\n",
    "        req = requests.get(links_only[i])\n",
    "        file.write(req.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
